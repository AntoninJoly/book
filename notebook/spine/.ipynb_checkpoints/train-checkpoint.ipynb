{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../../src/spine/model')\n",
    "sys.path.append('../../src/spine/dataset')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import AUC, Recall, Precision\n",
    "\n",
    "from retinanet import *\n",
    "from loss import *\n",
    "from label_encoder import *\n",
    "from vrt2coco import *\n",
    "\n",
    "data_dir = '../data/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "class DataGen(Sequence):\n",
    "    def __init__(self, df, path, input_cols, target_col, mode=None, batch_size=8, shuffle=True, img_size=640):\n",
    "        self.df = df\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.input_cols = input_cols\n",
    "        self.target_col = target_col\n",
    "        self.mode = mode\n",
    "        self.transform = A.Compose([A.HorizontalFlip(),\n",
    "#                                     A.Rotate(limit=15),\n",
    "#                                     A.RandomBrightnessContrast(),\n",
    "            #                        A.RandomScale(0.25),\n",
    "            #                        A.ChannelShuffle(),\n",
    "#                                     A.ShiftScaleRotate(),\n",
    "                                   ])\n",
    "        self.path = path\n",
    "        self.mode = mode\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.mode == 'train':\n",
    "            self.indexes = np.arange(len(self.df))\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def cropPad(self, img_path):\n",
    "        img = cv2.imread(os.path.join(self.path, img_path))\n",
    "        old_size = img.shape[:2] # old_size is in (height, width) format\n",
    "        ratio = float(self.img_size)/max(old_size)\n",
    "        new_size = tuple([int(x*ratio) for x in old_size])\n",
    "        img = cv2.resize(img, (new_size[1], new_size[0]))\n",
    "\n",
    "        delta_w = self.img_size - new_size[1]\n",
    "        delta_h = self.img_size - new_size[0]\n",
    "        top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "        left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "        img= cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT)\n",
    "               \n",
    "        return img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __classes__(self):\n",
    "        return self.df[self.target_col].to_numpy()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_size = min(self.batch_size, len(self.df) - index * self.batch_size)\n",
    "        X_img = np.zeros((batch_size, self.img_size, self.img_size, 3), dtype=int)\n",
    "        y = np.zeros((batch_size, len(self.target_col)), dtype=int)\n",
    "        \n",
    "        X_tab = self.df[index * self.batch_size : (index + 1) * self.batch_size][self.input_cols].values\n",
    "        patch_path = self.df[index * self.batch_size : (index + 1) * self.batch_size]['img_name']\n",
    "        \n",
    "        for i, img_path in enumerate(patch_path):\n",
    "            img = self.cropPad(img_path)\n",
    "            if self.mode == 'train' and self.transform != None:\n",
    "                X_img[i, ] = self.transform(image=img)['image']\n",
    "            else:\n",
    "                X_img[i, ] = img\n",
    "            y[i, ] = self.df[self.df['img_name']==img_path][self.target_col]\n",
    "        \n",
    "        return [X_img, X_tab], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df_smile, test_size=0.15, random_state=0)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 480\n",
    "train_datagen = DataGen(train_df, data_path, train_cols, target_col, img_size, 'train')\n",
    "val_datagen = DataGen(val_df, data_path, train_cols, target_col, img_size)\n",
    "test_datagen = DataGen(test_df, data_path, train_cols, target_col, img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_img, X_tab), y = train_datagen.__getitem__(0)\n",
    "print('Image: ', X_img.shape, 'Tabular: ', X_tab.shape, 'Label: ', y.shape)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for idx, (img, tab, label) in enumerate(zip(X_img, X_tab, y)):\n",
    "    plt.subplot(2, batch_size/2, idx+1)\n",
    "    plt.imshow(img[:, :, [2, 1, 0]])\n",
    "    plt.title('Label: %s'%(target_col[0] if label[0] else 'not ' + target_col[0]))\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"retinanet/\"\n",
    "\n",
    "num_classes = 1\n",
    "batch_size = 2\n",
    "\n",
    "learning_rates = [2.5e-06, 0.000625, 0.00125, 0.0025, 0.00025, 2.5e-05]\n",
    "learning_rate_boundaries = [125, 250, 500, 240000, 360000]\n",
    "learning_rate_fn = tf.optimizers.schedules.PiecewiseConstantDecay(boundaries=learning_rate_boundaries, \n",
    "                                                                  values=learning_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_backbone = get_backbone()\n",
    "loss_fn = RetinaNetLoss(num_classes)\n",
    "model = RetinaNet(num_classes, resnet50_backbone)\n",
    "\n",
    "optimizer = tf.optimizers.SGD(learning_rate=learning_rate_fn, momentum=0.9)\n",
    "model.compile(loss=loss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks_list = [ModelCheckpoint(filepath=os.path.join(model_dir, \"weights\" + \"_epoch_{epoch}\"),\n",
    "#                                   monitor=\"loss\",\n",
    "#                                   save_best_only=True,\n",
    "#                                   save_weights_only=True,\n",
    "#                                   verbose=1,)]\n",
    "\n",
    "filepath = '../model/spine.epoch{epoch:02d}-loss{val_loss:.2f}.hdf5'\n",
    "csv_logger = CSVLogger(\"../model/training_smile_binary.csv\", append=True)\n",
    "tb = TensorBoard(log_dir= \"../model/logs\", histogram_freq=0, write_graph=True, write_images=True)\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor=’val_acc’, verbose=1, save_best_only=True, mode=’max’)\n",
    "callbacks_list = [csv_logger, tb, checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(train_dataset.take(100),\n",
    "#                     validation_data=val_dataset.take(50),\n",
    "#                     epochs=10,\n",
    "#                     callbacks=callbacks_list,\n",
    "#                     verbose=1,)\n",
    "\n",
    "history =  model.fit_generator(generator=train_datagen,\n",
    "                               steps_per_epoch = train_datagen.__len__() // batch_size,\n",
    "                               epochs=10,\n",
    "                               validation_data = val_datagen,\n",
    "                               validation_steps = val_datagen.__len__() // batch_size,\n",
    "                               callbacks=callbacks_list,\n",
    "                               verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['acc'], label='train_iou')\n",
    "plt.plot(history.history['val_acc'], label='val_iou')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.keras.Input(shape=[None, None, 3], name=\"image\")\n",
    "predictions = model(image, training=False)\n",
    "detections = DecodePredictions(confidence_threshold=0.5)(image, predictions)\n",
    "inference_model = tf.keras.Model(inputs=image, outputs=detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(image):\n",
    "    image, _, ratio = resize_and_pad_image(image, jitter=None)\n",
    "    image = tf.keras.applications.resnet.preprocess_input(image)\n",
    "    return tf.expand_dims(image, axis=0), ratio\n",
    "\n",
    "val_dataset = tfds.load(\"coco/2017\", split=\"validation\", data_dir=\"data\")\n",
    "int2str = dataset_info.features[\"objects\"][\"label\"].int2str\n",
    "\n",
    "for sample in val_dataset.take(2):\n",
    "    image = tf.cast(sample[\"image\"], dtype=tf.float32)\n",
    "    input_image, ratio = prepare_image(image)\n",
    "    detections = inference_model.predict(input_image)\n",
    "    num_detections = detections.valid_detections[0]\n",
    "    class_names = [int2str(int(x)) for x in detections.nmsed_classes[0][:num_detections]]\n",
    "    visualize_detections(image,\n",
    "                         detections.nmsed_boxes[0][:num_detections] / ratio,\n",
    "                         class_names,\n",
    "                         detections.nmsed_scores[0][:num_detections],)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
