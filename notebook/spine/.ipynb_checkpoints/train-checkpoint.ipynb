{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../../src/spine/model')\n",
    "sys.path.append('../../src/spine/dataset')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import AUC, Recall, Precision\n",
    "from tensorflow.keras.utils import plot_model, Sequence\n",
    "import albumentations as A\n",
    "\n",
    "from retinanet import *\n",
    "from loss import *\n",
    "from label_encoder import *\n",
    "from vrt2coco import *\n",
    "from process_dataset import process_json_to_img\n",
    "\n",
    "data_dir = '../../data/spine'\n",
    "\n",
    "num_classes = 1\n",
    "batch_size = 8\n",
    "img_size = 480\n",
    "max_channel = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGen(Sequence):\n",
    "    def __init__(self, data_dir, path, max_channel, batch_size=8, img_size=640, shuffle=True, mode=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.path = path\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.mode = mode\n",
    "        self.max_channel = max_channel\n",
    "        self.class_names = {'book':1}\n",
    "        self.ratios = [0.5, 1.0, 2.0]\n",
    "        self.scales = [4 * 2**(i/3) for i in range(3)]\n",
    "        self.angles = [-np.pi/6, 0, np.pi/6] \n",
    "\n",
    "        self.transform_train = A.Compose([A.HorizontalFlip(),\n",
    "                                          A.Rotate(limit=1),\n",
    "                                          A.RandomBrightnessContrast(),\n",
    "                                          A.LongestMaxSize (max_size=self.img_size),\n",
    "#                                           A.Resize (height=self.img_size, width=self.img_size), \n",
    "                                          A.PadIfNeeded(min_height=self.img_size, min_width=self.img_size, border_mode=0),\n",
    "                                        \n",
    "                                          ],\n",
    "                                         keypoint_params=A.KeypointParams(format='xy'))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.mode == 'train':\n",
    "            self.indexes = np.arange(len(self.path))\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(self.indexes)\n",
    "   \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.path) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.data_generation(index)\n",
    "        return X, y\n",
    "    \n",
    "    def process_keypoints(self, vrt, shape):\n",
    "        target = np.ones((self.max_channel, 5)) * -1\n",
    "        pts, k = [], 0\n",
    "        for i in shape:\n",
    "            pts.append([k, k+i])\n",
    "            k+=i\n",
    "        for idx, i in enumerate(pts):\n",
    "            if idx ==self.max_channel:\n",
    "                break\n",
    "            cnt = np.array(vrt[i[0]:i[1]]).reshape(-1,2).astype(np.int0)\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            theta = cv2.minAreaRect(cnt)[2]\n",
    "            target[idx,:]= np.array([x, y, w, h, self.class_names['book']]).astype(float)        \n",
    "        return target\n",
    "    \n",
    "    def data_generation(self, index):\n",
    "        \n",
    "        X = np.zeros((self.batch_size, self.img_size, self.img_size, 3), dtype=int)\n",
    "        y = np.zeros((self.batch_size, self.max_channel, 5), dtype=float)\n",
    "        batch_path = self.path[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "\n",
    "        for idx, img_path in enumerate(batch_path):\n",
    "            _, img, vrt, vrt_shape = process_json_to_img(self.data_dir, path = img_path)\n",
    "            \n",
    "            if self.mode == 'train' or self.mode == 'val':\n",
    "                tr = self.transform_train(image=img,\n",
    "                                          keypoints=vrt)\n",
    "                X[idx, ] = tr['image']\n",
    "                y[idx, ] = self.process_keypoints(tr['keypoints'], vrt_shape)\n",
    "            else:\n",
    "                X[idx, ] = img\n",
    "#             y[i, ] = self.encode_sample(images_shape, gt_boxes[i], cls_ids[i])\n",
    "        return X, y\n",
    "    \n",
    "    def extract_target(self, ):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = [os.path.join(data_dir,i) for i in os.listdir(os.path.join(data_dir)) if os.path.splitext(i)[1]=='.json']\n",
    "\n",
    "train, val = train_test_split(json_path, test_size=0.3, random_state=0)\n",
    "val, test = train_test_split(val, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = DataGen(data_dir, train, max_channel, batch_size, img_size, True,'train')\n",
    "val_datagen = DataGen(data_dir, val, max_channel, batch_size, img_size, True, 'val')\n",
    "# test_datagen = DataGen(data_dir, test, batch_size, img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/val/test split & data generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:  (8, 480, 480, 3) Label:  (8, 20, 5)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"decode_predictions\" (type DecodePredictions).\n\nValue for attr 'T' of int32 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Sigmoid}}; Op<name=Sigmoid; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Sigmoid]\n\nCall arguments received:\n  • images=tf.Tensor(shape=(480, 480, 3), dtype=int32)\n  • predictions=array([[457,  84,  17, 335,   1],\n       [441,  82,  18, 337,   1],\n       [422,  61,  19, 358,   1],\n       [407,  61,  18, 358,   1],\n       [392,  61,  16, 358,   1],\n       [380,  61,  16, 358,   1],\n       [362,  60,  23, 359,   1],\n       [344,  61,  22, 358,   1],\n       [327,  61,  21, 359,   1],\n       [308,  61,  21, 358,   1],\n       [297,  61,  12, 358,   1],\n       [286,  61,  12, 358,   1],\n       [268,  61,  19, 358,   1],\n       [249,  61,  19, 358,   1],\n       [229,  66,  20, 353,   1],\n       [209,  67,  23, 351,   1],\n       [197,  66,  14, 353,   1],\n       [187,  66,  12, 353,   1],\n       [169,  68,  19, 351,   1],\n       [160,  68,  10, 351,   1]])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-39dd9b4b2ad6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mimg_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_res\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Git\\own git\\book\\src\\spine\\model\\retinanet.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, images, predictions)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mbox_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;31m# angle_predictions = predictions[:, 4]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[0mcls_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m         \u001b[0mboxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decode_box_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manchor_boxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"decode_predictions\" (type DecodePredictions).\n\nValue for attr 'T' of int32 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Sigmoid}}; Op<name=Sigmoid; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Sigmoid]\n\nCall arguments received:\n  • images=tf.Tensor(shape=(480, 480, 3), dtype=int32)\n  • predictions=array([[457,  84,  17, 335,   1],\n       [441,  82,  18, 337,   1],\n       [422,  61,  19, 358,   1],\n       [407,  61,  18, 358,   1],\n       [392,  61,  16, 358,   1],\n       [380,  61,  16, 358,   1],\n       [362,  60,  23, 359,   1],\n       [344,  61,  22, 358,   1],\n       [327,  61,  21, 359,   1],\n       [308,  61,  21, 358,   1],\n       [297,  61,  12, 358,   1],\n       [286,  61,  12, 358,   1],\n       [268,  61,  19, 358,   1],\n       [249,  61,  19, 358,   1],\n       [229,  66,  20, 353,   1],\n       [209,  67,  23, 351,   1],\n       [197,  66,  14, 353,   1],\n       [187,  66,  12, 353,   1],\n       [169,  68,  19, 351,   1],\n       [160,  68,  10, 351,   1]])"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x2520 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decode = DecodePredictions()\n",
    "X, y = train_datagen.__getitem__(0)\n",
    "print('Image: ', X.shape, 'Label: ', y.shape)\n",
    "\n",
    "plt.figure(figsize=(20,35))\n",
    "for idx, (img, pred) in enumerate(zip(X, y)):\n",
    "    \n",
    "    img_res = decode(img, pred)\n",
    "    plt.subplot(batch_size/2, 2, idx+1)\n",
    "    plt.imshow(img_res[:, :, [2, 1, 0]])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [2.5e-06, 0.000625, 0.00125, 0.0025, 0.00025, 2.5e-05]\n",
    "learning_rate_boundaries = [125, 250, 500, 240000, 360000]\n",
    "learning_rate_fn = tf.optimizers.schedules.PiecewiseConstantDecay(boundaries=learning_rate_boundaries, \n",
    "                                                                  values=learning_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_backbone = get_backbone()\n",
    "loss_fn = RetinaNetLoss(num_classes)\n",
    "model = RetinaNet(num_classes, resnet50_backbone)\n",
    "\n",
    "optimizer = tf.optimizers.SGD(learning_rate=learning_rate_fn, momentum=0.9)\n",
    "model.compile(loss=loss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks_list = [ModelCheckpoint(filepath=os.path.join(model_dir, \"weights\" + \"_epoch_{epoch}\"),\n",
    "#                                   monitor=\"loss\",\n",
    "#                                   save_best_only=True,\n",
    "#                                   save_weights_only=True,\n",
    "#                                   verbose=1,)]\n",
    "\n",
    "filepath = '../model/spine.epoch{epoch:02d}-loss{val_loss:.2f}.hdf5'\n",
    "csv_logger = CSVLogger(\"../model/training_smile_binary.csv\", append=True)\n",
    "tb = TensorBoard(log_dir= \"../model/logs\", histogram_freq=0, write_graph=True, write_images=True)\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_acc', verbose=1, save_best_only=True, mode=’max’)\n",
    "callbacks_list = [csv_logger, tb, checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(train_dataset.take(100),\n",
    "#                     validation_data=val_dataset.take(50),\n",
    "#                     epochs=10,\n",
    "#                     callbacks=callbacks_list,\n",
    "#                     verbose=1,)\n",
    "\n",
    "history =  model.fit_generator(generator=train_datagen,\n",
    "                               steps_per_epoch = train_datagen.__len__() // batch_size,\n",
    "                               epochs=10,\n",
    "                               validation_data = val_datagen,\n",
    "                               validation_steps = val_datagen.__len__() // batch_size,\n",
    "                               callbacks=callbacks_list,\n",
    "                               verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['acc'], label='train_iou')\n",
    "plt.plot(history.history['val_acc'], label='val_iou')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.keras.Input(shape=[None, None, 3], name=\"image\")\n",
    "predictions = model(image, training=False)\n",
    "detections = DecodePredictions(confidence_threshold=0.5)(image, predictions)\n",
    "inference_model = tf.keras.Model(inputs=image, outputs=detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(image):\n",
    "    image, _, ratio = resize_and_pad_image(image, jitter=None)\n",
    "    image = tf.keras.applications.resnet.preprocess_input(image)\n",
    "    return tf.expand_dims(image, axis=0), ratio\n",
    "\n",
    "val_dataset = tfds.load(\"coco/2017\", split=\"validation\", data_dir=\"data\")\n",
    "int2str = dataset_info.features[\"objects\"][\"label\"].int2str\n",
    "\n",
    "for sample in val_dataset.take(2):\n",
    "    image = tf.cast(sample[\"image\"], dtype=tf.float32)\n",
    "    input_image, ratio = prepare_image(image)\n",
    "    detections = inference_model.predict(input_image)\n",
    "    num_detections = detections.valid_detections[0]\n",
    "    class_names = [int2str(int(x)) for x in detections.nmsed_classes[0][:num_detections]]\n",
    "    visualize_detections(image,\n",
    "                         detections.nmsed_boxes[0][:num_detections] / ratio,\n",
    "                         class_names,\n",
    "                         detections.nmsed_scores[0][:num_detections],)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
