{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "# from wordcloud import WordCloud\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import stats\n",
    "from warnings import filterwarnings\n",
    "from IPython.core.display import display, HTML\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from pyquery import PyQuery \n",
    "import json\n",
    "import sys\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from aiohttp import ClientSession, ClientConnectorError\n",
    "import pathlib\n",
    "import sys\n",
    "import asyncio\n",
    "import time \n",
    "import aiohttp\n",
    "from aiohttp.client import ClientSession\n",
    "\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "sns.set(font_scale=1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271360, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISBN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0195153448</th>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002005018</th>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0060973129</th>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0374157065</th>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0393045218</th>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Book-Title  \\\n",
       "ISBN                                                            \n",
       "0195153448                                Classical Mythology   \n",
       "0002005018                                       Clara Callan   \n",
       "0060973129                               Decision in Normandy   \n",
       "0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "                     Book-Author Year-Of-Publication  \\\n",
       "ISBN                                                   \n",
       "0195153448    Mark P. O. Morford                2002   \n",
       "0002005018  Richard Bruce Wright                2001   \n",
       "0060973129          Carlo D'Este                1991   \n",
       "0374157065      Gina Bari Kolata                1999   \n",
       "0393045218       E. J. W. Barber                1999   \n",
       "\n",
       "                             Publisher  \\\n",
       "ISBN                                     \n",
       "0195153448     Oxford University Press   \n",
       "0002005018       HarperFlamingo Canada   \n",
       "0060973129             HarperPerennial   \n",
       "0374157065        Farrar Straus Giroux   \n",
       "0393045218  W. W. Norton &amp; Company   \n",
       "\n",
       "                                                  Image-URL-S  \\\n",
       "ISBN                                                            \n",
       "0195153448  http://images.amazon.com/images/P/0195153448.0...   \n",
       "0002005018  http://images.amazon.com/images/P/0002005018.0...   \n",
       "0060973129  http://images.amazon.com/images/P/0060973129.0...   \n",
       "0374157065  http://images.amazon.com/images/P/0374157065.0...   \n",
       "0393045218  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                                  Image-URL-M  \\\n",
       "ISBN                                                            \n",
       "0195153448  http://images.amazon.com/images/P/0195153448.0...   \n",
       "0002005018  http://images.amazon.com/images/P/0002005018.0...   \n",
       "0060973129  http://images.amazon.com/images/P/0060973129.0...   \n",
       "0374157065  http://images.amazon.com/images/P/0374157065.0...   \n",
       "0393045218  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                                  Image-URL-L  \n",
       "ISBN                                                           \n",
       "0195153448  http://images.amazon.com/images/P/0195153448.0...  \n",
       "0002005018  http://images.amazon.com/images/P/0002005018.0...  \n",
       "0060973129  http://images.amazon.com/images/P/0060973129.0...  \n",
       "0374157065  http://images.amazon.com/images/P/0374157065.0...  \n",
       "0393045218  http://images.amazon.com/images/P/0393045218.0...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = pd.read_csv('../../../data/recommendation/Books.csv',index_col=0)\n",
    "ratings = pd.read_csv('../../../data/recommendation/Ratings.csv')\n",
    "\n",
    "print(books.shape)\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(340556, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>0</th>\n",
       "      <th>weighted_average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISBN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0330299891</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.904964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0375404120</th>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.476393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0586045007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.389125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9022906116</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.047822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9032803328</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.389125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Book-Rating  0  weighted_average\n",
       "ISBN                                         \n",
       " 0330299891          3.0  2          2.904964\n",
       " 0375404120          1.5  2          2.476393\n",
       " 0586045007          0.0  1          2.389125\n",
       " 9022906116          3.5  2          3.047822\n",
       " 9032803328          0.0  1          2.389125"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=5\n",
    "R = ratings[['ISBN', 'Book-Rating']].groupby(['ISBN'], as_index=True).mean()\n",
    "C = ratings['Book-Rating'].mean()\n",
    "ratings = pd.concat([R, ratings.groupby(['ISBN'], as_index=True).size().to_frame()],axis=1)\n",
    "ratings['weighted_average'] = ratings.apply(lambda row: (row[0]/(row[0]+m))*row['Book-Rating'] + (m/(row[0]+m))*C, axis=1)\n",
    "\n",
    "ratings = ratings.rename(columns={'0':'Votes'})\n",
    "print(ratings.shape)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270151, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "      <th>weighted_average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISBN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0195153448</th>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>2.389125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002005018</th>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>4.386040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0060973129</th>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>3.666844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0374157065</th>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>3.833422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0393045218</th>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>2.389125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Book-Title  \\\n",
       "ISBN                                                            \n",
       "0195153448                                Classical Mythology   \n",
       "0002005018                                       Clara Callan   \n",
       "0060973129                               Decision in Normandy   \n",
       "0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "                     Book-Author Year-Of-Publication  \\\n",
       "ISBN                                                   \n",
       "0195153448    Mark P. O. Morford                2002   \n",
       "0002005018  Richard Bruce Wright                2001   \n",
       "0060973129          Carlo D'Este                1991   \n",
       "0374157065      Gina Bari Kolata                1999   \n",
       "0393045218       E. J. W. Barber                1999   \n",
       "\n",
       "                             Publisher  \\\n",
       "ISBN                                     \n",
       "0195153448     Oxford University Press   \n",
       "0002005018       HarperFlamingo Canada   \n",
       "0060973129             HarperPerennial   \n",
       "0374157065        Farrar Straus Giroux   \n",
       "0393045218  W. W. Norton &amp; Company   \n",
       "\n",
       "                                                  Image-URL-S  \\\n",
       "ISBN                                                            \n",
       "0195153448  http://images.amazon.com/images/P/0195153448.0...   \n",
       "0002005018  http://images.amazon.com/images/P/0002005018.0...   \n",
       "0060973129  http://images.amazon.com/images/P/0060973129.0...   \n",
       "0374157065  http://images.amazon.com/images/P/0374157065.0...   \n",
       "0393045218  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                                  Image-URL-M  \\\n",
       "ISBN                                                            \n",
       "0195153448  http://images.amazon.com/images/P/0195153448.0...   \n",
       "0002005018  http://images.amazon.com/images/P/0002005018.0...   \n",
       "0060973129  http://images.amazon.com/images/P/0060973129.0...   \n",
       "0374157065  http://images.amazon.com/images/P/0374157065.0...   \n",
       "0393045218  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                                  Image-URL-L  \\\n",
       "ISBN                                                            \n",
       "0195153448  http://images.amazon.com/images/P/0195153448.0...   \n",
       "0002005018  http://images.amazon.com/images/P/0002005018.0...   \n",
       "0060973129  http://images.amazon.com/images/P/0060973129.0...   \n",
       "0374157065  http://images.amazon.com/images/P/0374157065.0...   \n",
       "0393045218  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "            weighted_average  \n",
       "ISBN                          \n",
       "0195153448          2.389125  \n",
       "0002005018          4.386040  \n",
       "0060973129          3.666844  \n",
       "0374157065          3.833422  \n",
       "0393045218          2.389125  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = [idx for idx in books.index if idx in ratings.index]\n",
    "df = pd.concat([books.loc[index,:], ratings.loc[index, ['weighted_average']]], axis=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# data = {}\n",
    "# for isbn in tqdm(df.index):\n",
    "#     url = 'https://openlibrary.org/books/OL3597106M/%s'%(isbn)\n",
    "#     html = requests.get(url).text\n",
    "#     soup = BeautifulSoup(html, 'html.parser')\n",
    "#     res = [link.get('href') for link in soup.find_all('a') if link.get('href')!=None]\n",
    "#     data[isbn] = list(set([i.replace('/subjects/','') for i in res if i.startswith(('/subjects/'))]))\n",
    "    \n",
    "#     json.dump(data, open('data.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "# from tornado import ioloop, httpclient\n",
    "url_list = ['https://openlibrary.org/books/OL3597106M/%s'%(isbn) for isbn in df.index][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()\n",
    "# __import__('IPython').embed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "from threading import Thread\n",
    "import http.client, sys\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:32<00:00, 30.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "concurrent = 200\n",
    "data = {}\n",
    "\n",
    "def doWork():\n",
    "    while True:\n",
    "        url = q.get()\n",
    "        status, url = getStatus(url)\n",
    "        doSomethingWithResult(status, url)\n",
    "        q.task_done()\n",
    "\n",
    "def getStatus(ourl):\n",
    "    try:\n",
    "        url = urlparse(ourl)\n",
    "        conn = httplib.HTTPConnection(url.netloc)   \n",
    "        conn.request(\"HEAD\", url.path)\n",
    "        res = conn.getresponse()\n",
    "        return res.status, ourl\n",
    "    except:\n",
    "        return \"error\", ourl\n",
    "\n",
    "def doSomethingWithResult(status, url):\n",
    "    isbn = url.split('/')[-1]\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    res = [link.get('href') for link in soup.find_all('a') if link.get('href')!=None]\n",
    "    data[isbn] = list(set([i.replace('/subjects/','') for i in res if i.startswith(('/subjects/'))]))\n",
    "    \n",
    "#     print(status, url)\n",
    "\n",
    "q = Queue(concurrent * 2)\n",
    "for i in range(concurrent):\n",
    "    t = Thread(target=doWork)\n",
    "    t.daemon = True\n",
    "    t.start()\n",
    "try:\n",
    "    for url in tqdm(url_list):\n",
    "        q.put(url.strip())\n",
    "    q.join()\n",
    "except KeyboardInterrupt:\n",
    "    sys.exit(1)\n",
    "json.dump(data, open('data.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async def fetch_html(url: str, session: ClientSession, **kwargs) -> tuple:\n",
    "#     try:\n",
    "#         resp = await session.request(method=\"GET\", url=url, **kwargs)\n",
    "#     except ClientConnectorError:\n",
    "#         return (url, 404)\n",
    "#     return (url, resp.status)\n",
    "\n",
    "# async def make_requests(urls: set, **kwargs) -> None:\n",
    "#     async with ClientSession() as session:\n",
    "#         tasks = []\n",
    "#         for url in urls:\n",
    "#             tasks.append(fetch_html(url=url, session=session, **kwargs))\n",
    "#         results = await asyncio.gather(*tasks)\n",
    "\n",
    "#     for result in results:\n",
    "#         print(result)\n",
    "#         print(f'{result[1]} - {str(result[0])}')\n",
    "\n",
    "# urls = ['https://openlibrary.org/books/OL3597106M/%s'%(isbn) for isbn in df.index][:2]  \n",
    "# await make_requests(urls=urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action and Adventure\n",
    "# Classics\n",
    "# Comic Book or Graphic Novel\n",
    "# Detective and Mystery\n",
    "# Fantasy\n",
    "# Historical Fiction\n",
    "# Horror\n",
    "# Literary Fiction\n",
    "# Romance\n",
    "# Science Fiction (Sci-Fi)\n",
    "# Short Stories\n",
    "# Suspense and Thrillers\n",
    "# Women's Fiction\n",
    "# Biographies and Autobiographies\n",
    "# Cookbooks\n",
    "# Essays\n",
    "# History\n",
    "# Memoir\n",
    "# Poetry\n",
    "# Self-Help\n",
    "# True Crime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def clean_string(x):\n",
    "    try:\n",
    "        return str(x)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "df['type'].value_counts().plot(kind='bar') # Bar plot of anime type\n",
    "\n",
    "# Compute occurence of individual categories\n",
    "list_genre_flat = [clean_string(i).split(', ') for i in list(df_filtered['genre'].copy())]\n",
    "list_genre_flat = pd.Series([i for s in list_genre_flat for i in s]) # Flatenned list. Each occurence contribute to individual categories\n",
    "plt.subplot(1,2,2)\n",
    "list_genre_flat.value_counts().plot(kind='bar') # Bar plot of anime type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comedy genre is the category which is the most present in this filtered dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anime data correlation - TV show\n",
    "\n",
    "Is there a numerical correlation betweenn user's rating, number of episode and number of members belonging to anime community.\n",
    "We will focus on TV anime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.loc[df_filtered['type']=='TV']\n",
    "\n",
    "df_filtered['episodes'] = df_filtered['episodes'].apply(clean_numeric).astype('float') # Replace 0 value with NaN and clean\n",
    "df_filtered['rating'] = df_filtered['rating'].apply(clean_numeric).astype('float') # Transform to proper numerical data\n",
    "df_filtered['members'] = df_filtered['members'].apply(clean_numeric).astype('float') # Transform to proper numerical data\n",
    "\n",
    "df_filtered['episodes'] = df_filtered['episodes'].fillna(df_filtered['episodes'].median())\n",
    "df_filtered['rating'] = df_filtered['rating'].fillna(df_filtered['rating'].median())\n",
    "df_filtered['members'] = df_filtered['members'].fillna(df_filtered['members'].median())\n",
    "# Since we deleted row, it is important to reindex the dataframe, so we don't have missing index\n",
    "df_filtered = df_filtered.reset_index()\n",
    "list_index = df_filtered['index'].unique()\n",
    "\n",
    "df_filtered.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "plt.subplot(1,3,1)\n",
    "sns.distplot(df_filtered['episodes'])\n",
    "plt.subplot(1,3,2)\n",
    "sns.distplot(df_filtered['rating'])\n",
    "plt.subplot(1,3,3)\n",
    "sns.distplot(df_filtered['members'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1)\n",
    "corr = df_filtered[['episodes','rating','members']].corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "plt.figure(figsize=(9,9))\n",
    "\n",
    "with sns.axes_style(\"white\"):\n",
    "    ax = sns.heatmap(corr, mask=mask, vmax=.3, square=True, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "Set categorical data and their contribution the type TV (large number of episodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(x):\n",
    "    return df_filtered[df_filtered['name']==x].index.tolist()[0]\n",
    "def recommend_me(anime):\n",
    "    index = get_index(anime)\n",
    "    print('Here are 10 anime similar to', anime, ' - ', df_filtered.loc[index]['genre'],'\\n')\n",
    "    rec = []\n",
    "    for j in anime_indices[index][1:]:\n",
    "        print(df_filtered.loc[j]['name'],' - ', df_filtered.loc[j]['genre'])\n",
    "        rec.append([df_filtered.loc[j]['anime_id'], df_filtered.loc[j]['name'], df_filtered.loc[j]['genre']])\n",
    "    rec = pd.DataFrame(rec)\n",
    "#     rec = rec.transpose()\n",
    "    rec.columns = ['id', 'name', 'genre']\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating = pd.read_csv('../data/anime-recommendations-database/rating.csv')\n",
    "user_no = 1500\n",
    "\n",
    "# Select data by number of users\n",
    "df_rating = df_rating.head(df_rating[df_rating['user_id']==df_rating['user_id'].unique()[user_no]].index[-1])\n",
    "\n",
    "# Removing anime which where removed earlier in the notebook (list of anime). Reset index for avoinding conflict\n",
    "df_rating = df_rating[~df_rating['anime_id'].isin(list_index)].reset_index(drop=True)\n",
    "\n",
    "# User rating data investigation\n",
    "df_count = pd.DataFrame({'user_id': df_rating['user_id'].unique()})\n",
    "df_count['watched'] = [df_rating[df_rating['user_id']==i].shape[0] for i in df_rating['user_id'].unique()]\n",
    "df_count['vote_no'] = [len([j for j in list(df_rating[df_rating['user_id']==i]['rating']) if j != -1]) for i in df_rating['user_id'].unique()]\n",
    "df_count['ratio'] = df_count['vote_no'] / df_count['watched']\n",
    "\n",
    "# Establish 'like' ranges: 0 to 5 = Dislike; 5 to 7 = Neutral; over 7 = Like\n",
    "df_count['like'] = [len([j for j in list(df_rating[df_rating['user_id']==i]['rating']) if j !='NaN' and j >= 7]) for i in df_rating['user_id'].unique()]\n",
    "df_count['neutral'] = [len([j for j in list(df_rating[df_rating['user_id']==i]['rating']) if j !='NaN' and 5 <= j < 7]) for i in df_rating['user_id'].unique()]\n",
    "df_count['dislike'] = [len([j for j in list(df_rating[df_rating['user_id']==i]['rating']) if j !='NaN' and 0 <= j < 5]) for i in df_rating['user_id'].unique()]\n",
    "df_count['like_id'] = [[j[1] for j in list(zip(df_rating[df_rating['user_id']==i]['rating'],df_rating[df_rating['user_id']==i]['anime_id'])) if j[0] !='NaN' and j[0] >= 7] for i in df_rating['user_id'].unique()]\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "plt.figure(figsize=(24,8))\n",
    "plt.subplot(1,3,1)\n",
    "sns.distplot(df_count['vote_no'])\n",
    "plt.subplot(1,3,2)\n",
    "sns.distplot(df_count['watched'])\n",
    "plt.subplot(1,3,3)\n",
    "sns.distplot((100*df_count['ratio']).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate user common base - Collaborative filtering\n",
    "\n",
    "Check one user like history, check similar user and reccomend based on common viewing history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select users with more than 10 votes\n",
    "df_user = df_count[df_count['vote_no']>=10].reset_index(drop=True)\n",
    "df_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select user cluster with common like history (at least 10 items common, 10 different items). We investigate user_id = 3\n",
    "user_no = 5\n",
    "set_user = np.array(df_user[df_user['user_id'] == user_no]['like_id'].to_numpy()[0])\n",
    "df_user = df_user[df_user['user_id'] != user_no].reset_index(drop=True)\n",
    "\n",
    "# Check number of comon items in anime_id list\n",
    "df_user['common'] = [len([j for j in df_user[df_user['user_id'] == i]['like_id'].to_numpy()[0] if j in set_user]) for i in df_user['user_id'].tolist()]\n",
    "\n",
    "# Remove items with less than 10 common items\n",
    "df_user = df_user[df_user['common']>=10].reset_index(drop=True)\n",
    "df_user['different'] = [len([j for j in df_user[df_user['user_id'] == i]['like_id'].to_numpy()[0] if j not in set_user]) for i in df_user['user_id'].tolist()]\n",
    "df_user['unseen'] = [[j for j in df_user[df_user['user_id'] == i]['like_id'].to_numpy()[0] if j not in set_user] for i in df_user['user_id'].tolist()]\n",
    "\n",
    "df_user.sort_values(by='common', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# User 5 best ratings and corresponding genre\n",
    "user = df_rating[df_rating['user_id']==user_no]\n",
    "user = user[user['rating'] != -1].drop(['user_id'],axis=1).reset_index(drop=True)\n",
    "user = user[['rating','anime_id']]\n",
    "user['name'] = [str(df_filtered.loc[df_filtered['anime_id']==i]['name'].tolist())[2:-2] for i in user['anime_id']]\n",
    "user['genre'] = [str(df_filtered.loc[df_filtered['anime_id']==i]['genre'].tolist())[2:-2] for i in user['anime_id']]\n",
    "# user = user[user['user_id']==user_no]\n",
    "user.sort_values(by='rating',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count number of similar ID in unseen movies\n",
    "top_common = pd.value_counts(pd.Series([i for s in df_user['unseen'].tolist() for i in s]))\n",
    "test = pd.DataFrame(top_common)\n",
    "test['id'] = test.index\n",
    "test.columns = 'count','id'\n",
    "test['name'] = [str(df_filtered.loc[df_filtered['anime_id']==i]['name'].tolist())[2:-2] for i in test['id']]\n",
    "test['genre'] = [str(df_filtered.loc[df_filtered['anime_id']==i]['genre'].tolist())[2:-2] for i in test['id']]\n",
    "test = test.reset_index(drop=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item based recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_filtered = df_filtered['genre'].str.get_dummies(sep=',')\n",
    "X = pd.concat([genre_filtered, df_filtered['rating'], df_filtered['members']],axis=1)\n",
    "scaled = MaxAbsScaler()\n",
    "X = scaled.fit_transform(X)\n",
    "reg = NearestNeighbors(n_neighbors=11, algorithm='ball_tree').fit(X)\n",
    "anime_indices = reg.kneighbors(X)[1] # picks off the array for anime indices\n",
    "rec = recommend_me('Shingeki no Kyojin')\n",
    "rec.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add user similarity section - it also include dislike anime"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
